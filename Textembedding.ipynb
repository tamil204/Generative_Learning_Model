{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Jaccard Similarity"
      ],
      "metadata": {
        "id": "YPHQxcTMVTlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HPiv9kmfjmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c68bf83-c347-4cc8-9e8e-144df6268036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6470588235294118\n"
          ]
        }
      ],
      "source": [
        "#Text embedding\n",
        "sentence_1 = \"mountain is very beautiful to see\"\n",
        "sentence_2 = \"gargeous to see mountain\"\n",
        "def jaccard_similarity(sentence_1, sentence_2):\n",
        "  intersection_sen = len(set.intersection(*[set(sentence_1),set(sentence_2)]))\n",
        "  union_sen = len(set.union(*[set(sentence_1),set(sentence_2)]))\n",
        "  return intersection_sen/float(union_sen)\n",
        "\n",
        "sentence_1.split()\n",
        "sentence_2.split()\n",
        "print(jaccard_similarity(sentence_1, sentence_2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "import spacy\n",
        "import numpy as np\n",
        "# Load a spaCy language model (you need to download one first, e.g., 'en_core_web_sm')\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM93vJMraDTQ",
        "outputId": "10a5d560-82c5-4764-92de-69b8b245042b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "def squared_sen(x):\n",
        "    return round(sqrt(sum([a*a for a in x])), 3)\n",
        "\n",
        "def vector_magnitudes(vectors):\n",
        "    return [squared_sen(vector) for vector in vectors]\n",
        "\n",
        "embeddings_1 = [nlp(sentence).vector for sentence in sentence_1]\n",
        "magnitudes_1 = vector_magnitudes(embeddings_1)\n",
        "print(magnitudes_1)\n",
        "\n",
        "embeddings_2 = [nlp(sentence).vector for sentence in sentence_2]\n",
        "magnitudes_2 = vector_magnitudes(embeddings_2)\n",
        "print(magnitudes_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTZp_wzebrkC",
        "outputId": "b8de4eb8-177d-47c8-a7b9-788a0e3becf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.252, 8.921, 8.985, 8.541, 7.91, 7.577, 9.138, 8.541, 13.141, 9.138, 8.636, 13.141, 8.44, 9.627, 8.043, 7.49, 13.141, 8.113, 9.627, 7.577, 8.985, 7.91, 9.138, 8.245, 8.985, 7.869, 13.141, 7.91, 8.921, 13.141, 8.636, 9.627, 9.627]\n",
            "[8.695, 7.577, 8.043, 8.695, 9.627, 8.921, 8.985, 8.636, 13.141, 7.91, 8.921, 13.141, 8.636, 9.627, 9.627, 13.141, 9.252, 8.921, 8.985, 8.541, 7.91, 7.577, 9.138, 8.541]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Euclidean Distance"
      ],
      "metadata": {
        "id": "6TIK4kxuhb0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "def euclidean_distance(vec1, vec2):\n",
        "    return round(sqrt(sum((a - b) ** 2 for a, b in zip(vec1, vec2))), 3)\n",
        "\n",
        "embeddings_1 = [nlp(sentence).vector for sentence in sentence_1]\n",
        "embeddings_2 = [nlp(sentence).vector for sentence in sentence_2]\n",
        "\n",
        "distances = [euclidean_distance(vec1, vec2) for vec1, vec2 in zip(embeddings_1, embeddings_2)]\n",
        "print(distances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nVN2oQbddJQ",
        "outputId": "b21432ab-a30c-45f3-f9af-49872740d2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.679, 9.23, 7.545, 10.457, 8.267, 9.23, 8.49, 10.543, 0.0, 10.142, 8.042, 0.0, 8.704, 0.0, 7.013, 15.654, 15.919, 6.362, 6.51, 9.171, 7.724, 9.105, 0.0, 9.338]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Converting"
      ],
      "metadata": {
        "id": "01ST5xArhPPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize converting\n",
        "\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load a spaCy language model (you need to download one first, e.g., 'en_core_web_sm')\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#Text embedding\n",
        "sentence_1 = \"mountain is very beautiful to see\"\n",
        "sentence_2 = \"gargeous to see mountain\"\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer to the sentences\n",
        "vectorizer.fit([sentence_1, sentence_2])\n",
        "\n",
        "# Transform the sentences into vectors\n",
        "vector_1 = vectorizer.transform([sentence_1])\n",
        "vector_2 = vectorizer.transform([sentence_2])\n",
        "\n",
        "# Print the vectors\n",
        "print(\"Vector for sentence 1:\")\n",
        "print(vector_1.toarray())\n",
        "print(\"\\nVector for sentence 2:\")\n",
        "print(vector_2.toarray())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDSgY6IraWhp",
        "outputId": "2ccd5715-33a0-475d-90a2-770d839f8b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector for sentence 1:\n",
            "[[1 0 1 1 1 1 1]]\n",
            "\n",
            "Vector for sentence 2:\n",
            "[[0 1 0 1 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cosine similarity"
      ],
      "metadata": {
        "id": "_ctSMVHsI964"
      }
    },
    {
      "source": [
        "#cosine similarity\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "  dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
        "  magnitude_vec1 = sqrt(sum(a * a for a in vec1))\n",
        "  magnitude_vec2 = sqrt(sum(b * b for b in vec2))\n",
        "  return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
        "vector1 = embeddings_1[0]\n",
        "vector2 = embeddings_2[0]\n",
        "similarity = cosine_similarity(vector1, vector2)\n",
        "print(\"Cosine Similarity:\", similarity)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "KlJfWa-HdyIN",
        "outputId": "78372953-8cec-4659-c62f-f2ac83f3ea58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.5337411579499725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bag of words"
      ],
      "metadata": {
        "id": "bpjCbmnkJWrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentence_1 = \"mountain is very beautiful to see\"\n",
        "sentence_2 = \"gargeous to see mountain\"\n",
        "vocab = set(sentence_1.split() + sentence_2.split())\n",
        "\n",
        "def create_bow_vector(sentence, vocab):\n",
        "  vector = [0] * len(vocab)\n",
        "  for word in sentence.split():\n",
        "    if word in vocab:\n",
        "      vector[list(vocab).index(word)] += 1\n",
        "  return vector\n",
        "\n",
        "bow_vector_1 = create_bow_vector(sentence_1, vocab)\n",
        "bow_vector_2 = create_bow_vector(sentence_2, vocab)\n",
        "\n",
        "print(\"Bag-of-Words Vector for sentence 1:\", bow_vector_1)\n",
        "print(\"Bag-of-Words Vector for sentence 2:\", bow_vector_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POit0xhuVOfC",
        "outputId": "46af0aef-fce0-48fb-e2fb-8001d3470080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Vector for sentence 1: [1, 1, 1, 1, 1, 0, 1]\n",
            "Bag-of-Words Vector for sentence 2: [0, 0, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continous Bag of words"
      ],
      "metadata": {
        "id": "kkuz2Ypyfz_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# continos bag of words\n",
        "\n",
        "def generate_context_word_pairs(corpus, window_size):\n",
        "  context_word_pairs = []\n",
        "  for sentence in corpus:\n",
        "    for i, word in enumerate(sentence):\n",
        "      context = []\n",
        "      # Get words before the target word\n",
        "      for j in range(i - window_size, i):\n",
        "        if j >= 0:\n",
        "          context.append(sentence[j])\n",
        "      # Get words after the target word\n",
        "      for j in range(i + 1, i + window_size + 1):\n",
        "        if j < len(sentence):\n",
        "          context.append(sentence[j])\n",
        "      if context:  # Only add pairs with non-empty context\n",
        "        context_word_pairs.append((context, word))\n",
        "\n",
        "  return context_word_pairs\n",
        "\n",
        "# Example usage:\n",
        "corpus = [\n",
        "    [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"],\n",
        "    [\"a\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "]\n",
        "\n",
        "window_size = 2\n",
        "context_word_pairs = generate_context_word_pairs(corpus, window_size)\n",
        "\n",
        "for context, word in context_word_pairs:\n",
        "  print(f\"Context: {context}, Word: {word}\")\n",
        "\n",
        "# Now you can use these context-word pairs to train a CBOW model.\n",
        "# This would involve creating a vocabulary, mapping words to indices,\n",
        "# and building a neural network that predicts the target word given its context.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrATqFBleCbq",
        "outputId": "e8790408-1e31-411f-fc45-30ef0414e4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: ['quick', 'brown'], Word: the\n",
            "Context: ['the', 'brown', 'fox'], Word: quick\n",
            "Context: ['the', 'quick', 'fox', 'jumps'], Word: brown\n",
            "Context: ['quick', 'brown', 'jumps', 'over'], Word: fox\n",
            "Context: ['brown', 'fox', 'over', 'the'], Word: jumps\n",
            "Context: ['fox', 'jumps', 'the', 'lazy'], Word: over\n",
            "Context: ['jumps', 'over', 'lazy', 'dog'], Word: the\n",
            "Context: ['over', 'the', 'dog'], Word: lazy\n",
            "Context: ['the', 'lazy'], Word: dog\n",
            "Context: ['cat', 'sat'], Word: a\n",
            "Context: ['a', 'sat', 'on'], Word: cat\n",
            "Context: ['a', 'cat', 'on', 'the'], Word: sat\n",
            "Context: ['cat', 'sat', 'the', 'mat'], Word: on\n",
            "Context: ['sat', 'on', 'mat'], Word: the\n",
            "Context: ['on', 'the'], Word: mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text clustering"
      ],
      "metadata": {
        "id": "eeSGndQFKFNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k-means clustering for above programing\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Assuming you have your embeddings in a list called 'embeddings'\n",
        "# For example, using the spaCy embeddings from your previous code:\n",
        "embeddings = [nlp(sentence).vector for sentence in [sentence_1, sentence_2]]\n",
        "\n",
        "# Choose the number of clusters (k)\n",
        "k = 2\n",
        "\n",
        "# Create a KMeans object\n",
        "kmeans = KMeans(n_clusters=k)\n",
        "\n",
        "# Fit the model to your embeddings\n",
        "kmeans.fit(embeddings)\n",
        "\n",
        "# Get the cluster assignments for each sentence\n",
        "labels = kmeans.labels_\n",
        "print(\"Cluster Assignments:\", labels)\n",
        "\n",
        "# Get the cluster centers\n",
        "centers = kmeans.cluster_centers_\n",
        "print(\"Cluster Centers:\", centers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u70Hijqen5y",
        "outputId": "d056ab5a-418d-495d-c588-438f61d14be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Assignments: [0 1]\n",
            "Cluster Centers: [[-0.13056597 -0.10324321  0.04716581 -0.17158373 -0.91761899 -0.29834393\n",
            "   0.71635962  0.03759912 -0.10324943  0.3631146   0.09690655 -0.76376706\n",
            "  -0.16356631  0.56602079 -0.66687679  0.13439052  0.34797394 -0.700562\n",
            "  -0.29152271  0.22376704 -0.16747396  0.09409789 -0.78555465 -0.07938088\n",
            "  -0.08531129 -0.64172858  0.72307581  0.22541553 -0.19762675  0.35831079\n",
            "  -0.09355607  0.4766798   0.3932066  -0.08393378  0.49032846 -0.25784597\n",
            "  -0.34539744 -0.32916462  0.39670733  0.30233672  0.02041661 -0.31373152\n",
            "   0.08226699  0.48066464  0.37098348 -0.08990838  0.09107318 -0.1868359\n",
            "   0.39018884  0.01386564 -0.57389456  0.08593389 -0.32066861 -0.3436034\n",
            "  -0.1747634   0.55364507 -0.08726767  0.3616676  -0.15308623 -0.03415532\n",
            "  -0.07015631 -0.28114811 -0.27613759 -0.02510474  0.35842291  0.49779788\n",
            "  -0.18734144 -0.62526011  1.11536539  0.12866455  0.02784591 -0.48017403\n",
            "  -0.56910115  0.48310483 -0.38741454  0.01555627  0.00234882 -0.55606246\n",
            "   0.02598331  0.41143218 -0.30295101  0.11509048 -0.09891544 -0.02159662\n",
            "   0.21380693  0.38050556 -0.42637363 -0.10258446 -0.12106428  0.58057278\n",
            "   0.42319211 -0.40795973  0.44837463  0.47748092 -0.4087379   0.08826876]\n",
            " [-0.66053897 -1.02776289 -0.04855242 -0.01815265 -0.66345513 -0.0302831\n",
            "   0.5982219   0.13863564 -0.34217626  0.06025575 -0.22370291 -0.34781379\n",
            "  -0.24230279  0.45453298 -0.50676501 -0.56644994 -0.17910747 -1.0456363\n",
            "   0.30749297 -0.08507401  0.26574081  0.42827541 -0.90816987 -0.27653\n",
            "   0.1375583  -0.24361986  1.3381722   0.58924764 -0.20809121  0.33436885\n",
            "  -0.36389667  0.00265884  0.40694106 -0.18132286  0.45751834 -0.35818684\n",
            "  -0.24830344 -0.06713511  0.63342714  0.34213465  0.16298681 -0.25825337\n",
            "   0.11332276  0.66566855  0.09014671 -0.1367822   0.35505158 -0.535191\n",
            "   0.40604553 -0.53560752 -0.12128932  0.15941212 -0.06474435 -0.3282457\n",
            "  -0.31298339  0.35844904 -0.10803998  0.51550579 -0.34250051 -0.34569001\n",
            "  -0.5161342  -0.04597837 -0.22641149  0.01318151  0.2739661   0.04614409\n",
            "  -0.13038096 -0.36354446  0.55483979  0.8398667   0.18399599 -0.22185224\n",
            "   0.20819351  0.45271412 -0.14513101  0.22456096 -0.50637376  0.02335747\n",
            "  -0.17603719  0.02594578 -0.3331981   0.08532444 -0.65121484  0.40668464\n",
            "   0.04034936  0.42888093 -0.67947376 -0.09229583 -0.3255524   0.31933284\n",
            "  -0.15008563  0.09591559  0.71771449  0.78278726 -0.00479183  0.09127849]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ]
    }
  ]
}