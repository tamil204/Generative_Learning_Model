{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Zero Shot Prompt"
      ],
      "metadata": {
        "id": "KU_4Irk9XVTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Zero shot prompts\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Define the text dataset\n",
        "texts = [\n",
        "    \"I loved the food at the restaurant, and the service was excellent.\",\n",
        "    \"The movie was boring and too long.\",\n",
        "    \"The product arrived on time and works as expected.\",\n",
        "    \"I didn’t like the new update; it’s full of bugs.\"\n",
        "]\n",
        "\n",
        "# Define candidate labels\n",
        "candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Classify each text in the dataset\n",
        "for text in texts:\n",
        "    result = classifier(text, candidate_labels)\n",
        "    label = result['labels'][0]\n",
        "    score = result['scores'][0]\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Predicted Label: {label} (Score: {score:.2f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BknUvfO8VIk",
        "outputId": "9aa5acdf-c4ee-4945-dbd6-80bedce20316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'I loved the food at the restaurant, and the service was excellent.'\n",
            "Predicted Label: positive (Score: 0.97)\n",
            "\n",
            "Text: 'The movie was boring and too long.'\n",
            "Predicted Label: negative (Score: 0.98)\n",
            "\n",
            "Text: 'The product arrived on time and works as expected.'\n",
            "Predicted Label: positive (Score: 0.95)\n",
            "\n",
            "Text: 'I didn’t like the new update; it’s full of bugs.'\n",
            "Predicted Label: negative (Score: 0.99)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One shot Prompt"
      ],
      "metadata": {
        "id": "76MVeGM3XblW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One shot Prompts\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Define the text dataset\n",
        "texts = [\n",
        "    \"I loved the food at the restaurant, and the service was excellent.\",\n",
        "    \"The movie was boring and too long.\",\n",
        "    \"The product arrived on time and works as expected.\",\n",
        "    \"I didn’t like the new update; it’s full of bugs.\"\n",
        "]\n",
        "\n",
        "# Define candidate labels\n",
        "candidate_labels = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "# Provide a one-shot example\n",
        "one_shot_example = {\n",
        "    \"text\": \"The weather was great and the scenery was beautiful during our hike.\",\n",
        "    \"label\": \"positive\"\n",
        "}\n",
        "\n",
        "# Classify each text in the dataset using the one-shot example as context\n",
        "for text in texts:\n",
        "    # Combine the one-shot example with the target text\n",
        "    combined_text = f\"Example: {one_shot_example['text']} (Label: {one_shot_example['label']})\\n\\nTarget Text: {text}\"\n",
        "\n",
        "    # Perform classification\n",
        "    result = classifier(combined_text, candidate_labels)\n",
        "    label = result['labels'][0]\n",
        "    score = result['scores'][0]\n",
        "\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Predicted Label: {label} (Score: {score:.2f})\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRwRpfm88VFR",
        "outputId": "697d977f-a6ed-4a1d-8950-0803ad1e927d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'I loved the food at the restaurant, and the service was excellent.'\n",
            "Predicted Label: positive (Score: 0.98)\n",
            "\n",
            "Text: 'The movie was boring and too long.'\n",
            "Predicted Label: positive (Score: 0.89)\n",
            "\n",
            "Text: 'The product arrived on time and works as expected.'\n",
            "Predicted Label: positive (Score: 0.98)\n",
            "\n",
            "Text: 'I didn’t like the new update; it’s full of bugs.'\n",
            "Predicted Label: positive (Score: 0.96)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain of thoughts Prompt"
      ],
      "metadata": {
        "id": "oEzIipc-Xfa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chain of thoughts prompts\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the text generation pipeline with a model suitable for CoT reasoning\n",
        "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
        "\n",
        "# Define the text dataset\n",
        "texts = [\n",
        "    \"The new policy aims to reduce carbon emissions by 30% over the next decade.\",\n",
        "    \"Artificial intelligence can significantly improve healthcare outcomes.\",\n",
        "    \"Investing in renewable energy sources is crucial for sustainable development.\",\n",
        "    \"Learning a new language enhances cognitive abilities and cultural understanding.\"\n",
        "]\n",
        "\n",
        "# Chain of thought prompt for reasoning\n",
        "cot_prompt_template = (\n",
        "    \"Text: {text}\\n\"\n",
        "    \"Step 1: Identify the main point of the text.\\n\"\n",
        "    \"Step 2: Explain the implications or consequences of this point.\\n\"\n",
        "    \"Step 3: Discuss the potential benefits and challenges.\\n\"\n",
        "    \"Conclusion: Summarize the overall reasoning.\\n\"\n",
        ")\n",
        "\n",
        "# Generate reasoning for each text in the dataset\n",
        "for text in texts:\n",
        "    # Create a chain of thought prompt using the template\n",
        "    cot_prompt = cot_prompt_template.format(text=text)\n",
        "\n",
        "    # Generate the response using the text-generation model\n",
        "    result = generator(cot_prompt, max_length=200, num_return_sequences=1)\n",
        "\n",
        "    # Extract the generated text\n",
        "    generated_text = result[0]['generated_text']\n",
        "\n",
        "    print(f\"Original Text: {text}\\n\")\n",
        "    print(f\"Chain of Thought Reasoning:\\n{generated_text}\\n\")\n",
        "    print(\"-\" * 80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csP-F8Bp_kyg",
        "outputId": "eac9a66a-ac0e-4a8a-92ce-06138c488661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The new policy aims to reduce carbon emissions by 30% over the next decade.\n",
            "\n",
            "Chain of Thought Reasoning:\n",
            "Text: The new policy aims to reduce carbon emissions by 30% over the next decade.\n",
            "Step 1: Identify the main point of the text.\n",
            "Step 2: Explain the implications or consequences of this point.\n",
            "Step 3: Discuss the potential benefits and challenges.\n",
            "Conclusion: Summarize the overall reasoning.\n",
            "\"Here the 'ide' lies in the main point. If we are to reach the goal it will be to reduce our greenhouse gas emissions by 90%. But as this objective is more or less tied to the 'ide' then it is important to know what would make the most sense.\n",
            "The new policy aims at making real choices that are more and more about policy goals and how to address the key issues that affect global action on emissions reduction.\"\n",
            "*Source: Climate Change, 2011, available online at Climate Change website.\n",
            "(Images: Science paper P1677: http://www.sciencemag.org/science/journal/10.1126/\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Artificial intelligence can significantly improve healthcare outcomes.\n",
            "\n",
            "Chain of Thought Reasoning:\n",
            "Text: Artificial intelligence can significantly improve healthcare outcomes.\n",
            "Step 1: Identify the main point of the text.\n",
            "Step 2: Explain the implications or consequences of this point.\n",
            "Step 3: Discuss the potential benefits and challenges.\n",
            "Conclusion: Summarize the overall reasoning.\n",
            "Use Cases:\n",
            "A few of us have already written about what happens when a computer program creates data sets to help automate the work of healthcare. We can do just that.\n",
            "The point is to tell us what it will take to keep such data collection and analysis happening within a matter of seconds. Without any limitations or problems, we can easily achieve that goal.\n",
            "Once an automated data set comes into being, we can create new data sets to help facilitate and automate any tasks and processes that need to be carried out. This is what we call \"data processing.\" The tools that come with this language are built on top of standard programming languages or languages and can, when used correctly, automatically build and operate\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: Investing in renewable energy sources is crucial for sustainable development.\n",
            "\n",
            "Chain of Thought Reasoning:\n",
            "Text: Investing in renewable energy sources is crucial for sustainable development.\n",
            "Step 1: Identify the main point of the text.\n",
            "Step 2: Explain the implications or consequences of this point.\n",
            "Step 3: Discuss the potential benefits and challenges.\n",
            "Conclusion: Summarize the overall reasoning.\n",
            "Step 4: Make a donation.\n",
            "If you are still reading this post, please consider supporting an organization that is advancing sustainable energy infrastructure.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Original Text: Learning a new language enhances cognitive abilities and cultural understanding.\n",
            "\n",
            "Chain of Thought Reasoning:\n",
            "Text: Learning a new language enhances cognitive abilities and cultural understanding.\n",
            "Step 1: Identify the main point of the text.\n",
            "Step 2: Explain the implications or consequences of this point.\n",
            "Step 3: Discuss the potential benefits and challenges.\n",
            "Conclusion: Summarize the overall reasoning.\n",
            "Note\n",
            "1. In paragraph 1, I also introduced the main points of the Text-Learning Study. These points are the areas covered by the text and are not the only ones relevant to this topic. If I miss a point, please send me a email (see the note at foot of the article).\n",
            "2. In text section, I introduced a question and answer system. Here's a sample of my answer to the question and answer system:\n",
            "How well do you use word processing? I'm very pleased to hear that word processing abilities have improved tremendously in people with multiple language preferences, and those with a few languages and two language types well into their early 20s can learn all\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}